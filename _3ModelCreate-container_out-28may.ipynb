{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#/home/user/data/container/train+test+val 10K aug+ 1636 real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.12.0\n",
      "Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is: C:\\Users\\is95217\\PycharmProjects\\source\\turkishplate\\_1 Container\n",
      "Data: C:/Users/is95217/data\n",
      "Source code: C:/Users/is95217/PycharmProjects/source/turkishplate/_1 Container/\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"/gpu:0\"  \n",
    "\n",
    "working_dir = os.getcwd()\n",
    "print(\"Working directory is:\",working_dir)\n",
    "sys.path.append(working_dir)  # To find local version of the library\n",
    "\n",
    "linux= False\n",
    "\n",
    "if linux:\n",
    "    ROOT_DIR = os.path.join(\"/home/user/gullseye/sentinel\") #linux        \n",
    "    DATA_DIR = \"/home/user/data/evrim\" \n",
    "else:    \n",
    "    ROOT_DIR = os.path.join(\"C:/Users/is95217/PycharmProjects/source/turkishplate/_1 Container/\") #win\n",
    "    DATA_DIR = \"C:/Users/is95217/data\" #win\n",
    "    \n",
    "sys.path.append(ROOT_DIR + \"/api\")\n",
    "\n",
    "import Modelopcontainer as p # \n",
    "\n",
    "print(\"Data:\", DATA_DIR)\n",
    "print(\"Source code:\", ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model description and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate=0.02\n",
    "ibatchsize=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 64, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 32, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32)       0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 37)       37925       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 37)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,871,669\n",
      "Trainable params: 4,871,669\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      "53/53 [==============================] - 94s 2s/step - loss: 40.8707 - acc: 0.0000e+00 - val_loss: 30.8667 - val_acc: 0.0000e+00\n",
      "SavedC:/Users/is95217/PycharmProjects/source/turkishplate/_1 Container//weights/model_container_out model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model2 = p.train2gru(128,32, #imgw,imgh  #HEİGHT küçültüldü\n",
    "#model2 = p.train2gru(128,32,\n",
    "model2 = p.train2gru(128,64, #imgw,imgh  --> SONRA BUNU YAP                     \n",
    "                     DATA_DIR, #path\n",
    "                     False,         #load             \n",
    "                     ROOT_DIR + \"/weights/model_container_out\",  #path & name_model\n",
    "                     1, #epoch\n",
    "                     lrate,#learning rate\n",
    "                     ibatchsize) \n",
    "\n",
    "#out-> Epoch 30/30 8582/8582 loss: 0.0027 - acc: 0.9990 - val_loss: 0.7792 - val_acc: 0.9124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Get training and test loss histories\n",
    "training_loss = model2.history.history['loss']\n",
    "test_loss = model2.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model2.history.history['acc']\n",
    "test_acc = model2.history.history['val_acc']\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_acc, 'r--')\n",
    "plt.plot(epoch_count, test_acc, 'b-')\n",
    "plt.legend(['Training acc', 'Test acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "tf_config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_detection = tf.Graph()\n",
    "\n",
    "with graph_detection.as_default():\n",
    "    session_detection = tf.Session(graph = graph_detection, config=tf_config) \n",
    "    with session_detection.as_default():\n",
    "        #load model\n",
    "        loaded_model=p.load_model(ROOT_DIR +'/weights/model_container_out',lrate) #mix pics from port and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_filepath = DATA_DIR + '/test/ACJG6440259.jpg' #ok\n",
    "#img_filepath = DATA_DIR + '/test/APZU3711995.R 20190315233027.jpg' #not ok \n",
    "img_filepath = DATA_DIR + '/test/ADMU12061392.jpg' #not ok -> DRHU6747850\n",
    "image = cv2.imread(img_filepath)\n",
    "\n",
    "with graph_detection.as_default():\n",
    "     with session_detection.as_default():\n",
    "            #predicted_text = p.predict_single_plate(session_detection,loaded_model,image,128,32)#input directory of pic\n",
    "            predicted_text = p.predict_single_plate(session_detection,loaded_model,image,128,64)#input directory of pic\n",
    "            print(predicted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full test set predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filepath=DATA_DIR + '/test/' #sonda slash olacak!\n",
    "#img_filepath = '/home/user/data/container/4straightgullseye -ters/' \n",
    "#img_filepath= '/home/user/data/container/4straightgullseye/'\n",
    "\n",
    "cnt_test= len(os.listdir(img_filepath))\n",
    "cnt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched=0\n",
    "nonmatched=0\n",
    "notread=0\n",
    "for fname in os.listdir(img_filepath):\n",
    "    \n",
    "    try:      \n",
    "        image = cv2.imread(img_filepath + fname)\n",
    "        fn = fname.split('.')   \n",
    "        fn= fn[0][0:11]\n",
    "        #print(fn)\n",
    "        with graph_detection.as_default():\n",
    "             with session_detection.as_default():\n",
    "                predicted_text = p.predict_single_plate(session_detection,loaded_model,image,128,64)#input directory of pic   \n",
    "        if ''.join(predicted_text) == fn:\n",
    "            matched +=1\n",
    "            #print('matched predicted=',''.join(predicted_text),', real= ',fn,\", fullname=\",fname)\n",
    "        else:\n",
    "            print('notmatched predicted=',''.join(predicted_text),', real= ',fn,\", fullname=\",fname)            \n",
    "            try:\n",
    "                #os.remove(img_filepath + fname)\n",
    "                x=1\n",
    "            except:\n",
    "                print(\"remove error\")            \n",
    "            nonmatched +=1\n",
    "    except:\n",
    "        print(\"image not read \",img_filepath + fname)\n",
    "        notread +=1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('matched:', matched,\",nonmatched:\",nonmatched, \",not read:\",notread,\",accuracy:\",matched/cnt_test*100,\",total:\",cnt_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('matched:', matched,\",nonmatched:\",nonmatched, \",not read:\",notread,\",accuracy:\",matched/cnt_test*100,cnt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR=0.01 3GRU matched: 433 ,nonmatched: 238 ,not read: 0 ,accuracy: 64.53055141579732\n",
    "#lr=0.02 2gru model_out5 with 2000 aug+ 1600 real -> matched: 280 ,nonmatched: 84 ,not read: 0 ,accuracy: 76.92307692307693\n",
    "#4000 aug +1600 real                              -> matched: 441 ,nonmatched: 123 ,not read: 0 ,accuracy: 78.19148936170212\n",
    "#with spaces matched: 438 ,nonmatched: 126 ,not read: 0 ,accuracy: 77.6595744680851\n",
    "\n",
    "#out4 3000 augmente matched: 296 ,nonmatched: 5 ,not read: 0 ,accuracy: 98.33887043189368 301\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
