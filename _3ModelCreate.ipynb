{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.10.1\n",
      "Keras version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is: /home/user/Source/Evrim/Turkishplate\n"
     ]
    }
   ],
   "source": [
    "working_dir = os.getcwd()\n",
    "print(\"Working directory is:\",working_dir)\n",
    "sys.path.append(working_dir)  # To find local version of the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(\"/home/user/Source/Evrim/Turkishplate\") #linux\n",
    "#ROOT_DIR = os.path.join(\"C:/Users/is95217/source/plate/turkishplate\") #win\n",
    "sys.path.append(ROOT_DIR + \"/Python\")\n",
    "import PPlate as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: /home/user/Source/data/dataEvrim/Original_15Kcrop_distributed\n",
      "Source code: /home/user/Source/Evrim/Turkishplate\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/home/user/Source/data/dataEvrim/Original_15Kcrop_distributed\"  #linux\n",
    "#DATA_DIR = \"C:/Users/is95217/data/Original_15Kcrop_distributed\" #win\n",
    "print(\"Data:\", DATA_DIR)\n",
    "print(\"Source code:\", ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model description and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 34)       34850       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 34)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,868,594\n",
      "Trainable params: 4,868,594\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      " 4643/12535 [==========>...................] - ETA: 10:11 - loss: 2.8825 - acc: 0.6878"
     ]
    }
   ],
   "source": [
    "#                imgw,imgh,path,load, path & name_model, epoch_cnt\n",
    "model = p.train(128,64,DATA_DIR,False, ROOT_DIR + \"/Model/model15k\", 5)  #epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Get training and test loss histories\n",
    "training_loss = model.history.history['loss']\n",
    "test_loss = model.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model.history.history['acc']\n",
    "test_acc = model.history.history['val_acc']\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_acc, 'r--')\n",
    "plt.plot(epoch_count, test_acc, 'b-')\n",
    "plt.legend(['Training acc', 'Test acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tiger_test = TextImageGenerator('../data/anpr_ocr__test', 'test', 128, 64, 8, 4)\n",
    "tiger_test.build_data()\n",
    "\n",
    "net_inp = model.get_layer(name='the_input').input\n",
    "net_out = model.get_layer(name='softmax').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp_value, _ in tiger_test.next_batch():\n",
    "    bs = inp_value['the_input'].shape[0]\n",
    "    X_data = inp_value['the_input']\n",
    "    \n",
    "    net_out_value = sess.run(net_out, feed_dict={net_inp:X_data})\n",
    "    pred_texts = decode_batch(net_out_value)\n",
    "    \n",
    "    labels = inp_value['the_labels']\n",
    "    texts = []\n",
    "    #print(\"labels:\",labels)\n",
    "    \n",
    "    for label in labels:\n",
    "        text = labels_to_text(label) \n",
    "        #print(\"text:\",text)\n",
    "        #text = ''.join(list(map(lambda x: letters[int(x)], label)))\n",
    "        texts.append(text)\n",
    "        #print(\"texts:\",texts)\n",
    "    \n",
    "    for i in range(bs):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        outer = gridspec.GridSpec(2, 1, wspace=10, hspace=0.1)\n",
    "        ax1 = plt.Subplot(fig, outer[0])\n",
    "        fig.add_subplot(ax1)\n",
    "        ax2 = plt.Subplot(fig, outer[1])\n",
    "        fig.add_subplot(ax2)\n",
    "        print('Predicted: %s\\nTrue: %s' % (pred_texts[i], texts[i]))\n",
    "        img = X_data[i][:, :, 0].T\n",
    "        ax1.set_title('Input img')\n",
    "        ax1.imshow(img, cmap='gray')\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax2.set_title('Activations')\n",
    "        ax2.imshow(net_out_value[i].T, cmap='binary', interpolation='nearest')\n",
    "        ax2.set_yticks(list(range(len(letters) + 1)))\n",
    "        ax2.set_yticklabels(letters + ['blank'])\n",
    "        ax2.grid(False)\n",
    "        for h in np.arange(-0.5, len(letters) + 1 + 0.5, 1):\n",
    "            ax2.axhline(h, linestyle='-', color='k', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        #ax.axvline(x, linestyle='--', color='k')\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger_test = TextImageGenerator('../data/anpr_ocr__test', 'test', 128, 64, 461, 4)\n",
    "tiger_test.build_data()\n",
    "\n",
    "net_inp = model.get_layer(name='the_input').input\n",
    "net_out = model.get_layer(name='softmax').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp_value, _ in tiger_test.next_batch():\n",
    "    matched=0\n",
    "    bs = inp_value['the_input'].shape[0]\n",
    "    X_data = inp_value['the_input']\n",
    "    \n",
    "    net_out_value = sess.run(net_out, feed_dict={net_inp:X_data})\n",
    "    pred_texts = decode_batch(net_out_value)\n",
    "    \n",
    "    labels = inp_value['the_labels']\n",
    "    texts = []\n",
    "    #print(\"labels:\",labels)\n",
    "    \n",
    "    for label in labels:\n",
    "        text = labels_to_text(label) \n",
    "        #print(\"text:\",text)\n",
    "        #text = ''.join(list(map(lambda x: letters[int(x)], label)))\n",
    "        texts.append(text)\n",
    "        #print(\"texts:\",texts)\n",
    "    \n",
    "    for i in range(bs):\n",
    "        #print('Predicted: %s True: %s i: %s lpred: %s ltrue: %s' % \n",
    "        #      (pred_texts[i], texts[i],str(i),len(pred_texts[i]),len(texts[i])))\n",
    "        \n",
    "        if pred_texts[i] == texts[i]:\n",
    "            matched = matched+1\n",
    "        else:\n",
    "            print('wrong Predicted: %s True: %s i: %s lpred: %s ltrue: %s' % \n",
    "              (pred_texts[i], texts[i],str(i),len(pred_texts[i]),len(texts[i])))\n",
    "            \n",
    "    print(\"matched=\",matched, \",total=\",i, \"TP: %\", round(matched/i, 2) *100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
