{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Keras version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__) \n",
    "print('Keras version:', keras.__version__)\n",
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "#import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"anpr_ocr__train\": 8\n",
      "Max plate length in \"anpr_ocr__train\": 8\n",
      "33 33 33\n",
      "Letters: 0 1 2 3 4 5 6 7 8 9 A B C D E F G H I J K L M N O P R S T U V Y Z\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z']\n",
      "33\n",
      "letters_val: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.dirname(os.path.realpath('Textgen')) + \"/python\")\n",
    "import Textgen as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "fmodel='lr0.02_mom0.9'\n",
    "\n",
    "json_file = open(fmodel + '.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(fmodel + '.h5')\n",
    "print(\"Loaded model from disk\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "# Compile model\n",
    "loaded_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Model' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d7a9b368c54b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Get training and test loss histories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Model' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Get training and test loss histories\n",
    "training_loss = loaded_model['loss']\n",
    "test_loss = loaded_model.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tiger_test = t.TextImageGenerator('../data/anpr_ocr__test', 'test', 128, 64, 8, 4) # batch size \n",
    "tiger_test.build_data()\n",
    "\n",
    "net_inp = loaded_model.get_layer(name='the_input').input\n",
    "net_out = loaded_model.get_layer(name='softmax').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'the_input:0' shape=(?, 128, 64, 1) dtype=float32>,\n",
       " <tf.Tensor 'softmax/truediv:0' shape=(?, 32, 34) dtype=float32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_inp,net_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 64, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger_test.batch_size,tiger_test.img_h,tiger_test.img_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_input: (8, 128, 64, 1)\n",
      "the_labels: (8, 8)\n",
      "input_length: (8, 1)\n",
      "label_length: (8, 1)\n",
      "labels: [ 0.  1. 11. 17.  3.  0.  7. 34.]\n",
      "labels: [ 0.  1. 11. 17.  3.  0.  7. 34.]\n",
      "labels: [ 0.  1. 11. 17.  3.  0.  7. 34.]\n",
      "labels: [ 0.  1. 13. 14. 20.  1.  1. 34.]\n",
      "labels: [ 0.  1. 13. 15. 10.  0.  3. 34.]\n",
      "labels: [ 0.  1. 13. 18. 20.  9.  7. 34.]\n",
      "labels: [ 0.  1. 13. 19. 22.  5.  2. 34.]\n",
      "labels: [ 0.  3. 15. 12.  1.  8.  4. 34.]\n"
     ]
    }
   ],
   "source": [
    "for inp_value, _ in tiger_test.next_batch(K):   \n",
    "    nbr_example = inp_value['the_input'].shape[0]    \n",
    "    print('the_input:',np.shape(inp_value['the_input']))\n",
    "    print('the_labels:',np.shape(inp_value['the_labels']))\n",
    "    print('input_length:',np.shape(inp_value['input_length']))\n",
    "    print('label_length:',np.shape(inp_value['label_length']))\n",
    "    for i  in range(nbr_example):\n",
    "        print(\"labels:\", inp_value['the_labels'][i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger_test = t.TextImageGenerator('../data/anpr_ocr__test', 'test', 128, 64, 461, 4) # batch size \n",
    "tiger_test.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong Predicted: 06BB17 True: 06BHB17 i: 13 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 06BCD70 True: 06BID70 i: 16 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 06DK5309 True: 06DK5303 i: 24 len_pred: 8 len_true: 8\n",
      "wrong Predicted: 06DK507 True: 06DK5907 i: 29 len_pred: 7 len_true: 8\n",
      "wrong Predicted: 34Y1288 True: 13TN1268 i: 40 len_pred: 7 len_true: 8\n",
      "wrong Predicted: 41YG0941 True: 41YC004 i: 61 len_pred: 8 len_true: 7\n",
      "wrong Predicted: 43HP98 True: 43HP983 i: 74 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 52K35088 True: 52K3508 i: 76 len_pred: 8 len_true: 7\n",
      "wrong Predicted: 81EN209 True: 81EH209 i: 82 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 01DFA25 True: 01DFA251 i: 87 len_pred: 7 len_true: 8\n",
      "wrong Predicted: 06BAF319 True: 06BJF37 i: 117 len_pred: 8 len_true: 7\n",
      "wrong Predicted: 6BP7019 True: 06BR7019 i: 118 len_pred: 7 len_true: 8\n",
      "wrong Predicted: 08FJ7246 True: 06FJ7246 i: 137 len_pred: 8 len_true: 8\n",
      "wrong Predicted: 06HC6P True: 06HC609 i: 142 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 06JDF31 True: 06JOF31 i: 146 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 140Y5208 True: 10Y5208 i: 192 len_pred: 8 len_true: 7\n",
      "wrong Predicted: 16AD05 True: 16MAD05 i: 213 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 34JZ80651 True: 34JZ8065 i: 227 len_pred: 9 len_true: 8\n",
      "wrong Predicted: 41E152 True: 41YE152 i: 255 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 44H369 True: 41YH369 i: 278 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 41YT886 True: 41YT686 i: 332 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 41YU004 True: 41YV004 i: 337 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 41YN670 True: 41YV670 i: 344 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 42CCK41 True: 42CCK48 i: 355 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 42CNU14 True: 42CNU141 i: 356 len_pred: 7 len_true: 8\n",
      "wrong Predicted: 42SA31 True: 42CSA31 i: 358 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 43PG4224 True: 43PG424 i: 389 len_pred: 8 len_true: 7\n",
      "wrong Predicted: 43PNR757 True: 43PN757 i: 397 len_pred: 8 len_true: 7\n",
      "wrong Predicted: 43UT621 True: 43UY621 i: 404 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 50F302 True: 50LF302 i: 412 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 54NC590 True: 54HC590 i: 421 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 59AVM62 True: 55AVM62 i: 423 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 66D2343 True: 60D2343 i: 436 len_pred: 7 len_true: 7\n",
      "wrong Predicted: 34EY7532 True: 64EY7532 i: 437 len_pred: 8 len_true: 8\n",
      "wrong Predicted: 7DR747 True: 67DR747 i: 440 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 7EF039 True: 70EF039 i: 444 len_pred: 6 len_true: 7\n",
      "wrong Predicted: 785B611 True: 78SB611 i: 457 len_pred: 7 len_true: 7\n",
      "matched= 424 ,total= 461 TP: % 92.0\n"
     ]
    }
   ],
   "source": [
    "for inp_value, _ in tiger_test.next_batch(K):\n",
    "    matched=0\n",
    "    non_matched=0\n",
    "    testset_cnt = inp_value['the_input'].shape[0]\n",
    "    X_data = inp_value['the_input']\n",
    "    \n",
    "    net_out_value = sess.run(net_out, feed_dict={net_inp:X_data})\n",
    "    pred_texts = t.decode_batch(net_out_value)\n",
    "    \n",
    "    labels = inp_value['the_labels']\n",
    "    texts = []     \n",
    "    \n",
    "    for label in labels:\n",
    "        text = t.labels_to_text(label)        \n",
    "        texts.append(text)       \n",
    "    \n",
    "    for cnt in range(testset_cnt):        \n",
    "        \n",
    "        if pred_texts[cnt] == texts[cnt]:\n",
    "            matched += 1            \n",
    "        else:\n",
    "            non_matched +=  1\n",
    "            print('wrong Predicted: %s True: %s i: %s len_pred: %s len_true: %s' % (pred_texts[cnt], texts[cnt],str(cnt),\n",
    "                                                                              len(pred_texts[cnt]),len(texts[cnt])))\n",
    "            \n",
    "    print(\"matched=\",matched, \",total=\",testset_cnt , \"TP: %\", round(matched/testset_cnt, 2) * 100)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If evaluating from data tensors, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f3bd6c766932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m             raise ValueError('If evaluating from data tensors, '\n\u001b[0m\u001b[0;32m   1094\u001b[0m                              \u001b[1;34m'you should specify the `steps` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m                              'argument.')\n",
      "\u001b[1;31mValueError\u001b[0m: If evaluating from data tensors, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\"\"\"    \n",
    "inputs = {\n",
    "            'the_input': X_data,\n",
    "            'the_labels': Y_data,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            #'source_str': source_str\n",
    "        }\n",
    "#outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "\n",
    "XX = [X['the_input'], \n",
    "      X['the_labels'], \n",
    "      X['input_length'], \n",
    "      X['label_length']]\n",
    "\"\"\"\n",
    "\n",
    "#model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "scores = loaded_model.evaluate()\n",
    "for i in range(len(scores)):\n",
    "    print(\"\\n%s: %.2f%%\" % (loaded_model.metrics_names[i], scores[i]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-ae070c63704b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtiger_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'the_input'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "X=tiger_test.next_batch(K)\n",
    "X['the_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
